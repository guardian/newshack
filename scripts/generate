#! /usr/bin/env ruby

require 'json'
require 'open-uri'
require 'date'
require 'curb'
require 'trollop'
require 'nokogiri'

CONF = Trollop::options do
	opt :date_start, "Start of date range. Format YYYY-MM-DD.", :type => :string, :required => true, :short => "-s"
	opt :date_end, "End of date range Format YYYY-MM-DD", :type => :string, :required => true, :short => "-e"
	#pt :tag_filter, "Tags to include/exclude", :type => :string, :default => "type/article,-tone/minutebyminute"
	opt :api_root, "Root Content API endpoint", :type => :string, :default => "http://prod-mq-elb.content.guardianapis.com/api", :short => "-a"
	opt :api_key, "Content API key", :type => :string, :default => "ca-body-link-analysis", :short => "-k"
	opt :slowdown, "Number of seconds to wait between requests", :type => :integer, :default => 0, :short => "-w"
	opt :outfile, "Name of file to save output to", :type => :string, :short => "-o"
end

DEFAULT_PARAMS = {
	format: 'json',
	pageSize: 50,
	userTier: 'internal',
	apiKey: CONF.api_key,
}

CONF['tag_filer'] = 'world/us-government-shutdown-2013'

def make_uri(endpoint, params)
	qs = params.map {|k, v| "#{k}=#{v}"}.join('&')

	return "#{CONF.api_root}/#{endpoint}?#{qs}"
end

def request(endpoint, params)
	params.merge! DEFAULT_PARAMS

	puts "starting query: #{endpoint}?#{params.map {|k, v| "#{k}=#{v}"}.join('&')}"
	puts "requesting page 1"

	res  = Curl.get(make_uri(endpoint, params))
	data = JSON.parse(res.body_str)['response']

	pages = data['pages']
	puts "#{pages - 1} more pages of results to get"
	$stdout.flush

	return data['results'] if pages == 1

	results = [data['results']]

	(2..pages).to_a.each do |page|
		puts "requesting page #{page}"
		$stdout.flush
		res = Curl.get(make_uri(endpoint, params.merge(page: page)))
		data = JSON.parse(res.body_str)['response']

		results << data['results']
		sleep CONF.slowdown
	end

	return results.flatten
end

date_start = DateTime.new(*CONF.date_start.split('-').map(&:to_i))
date_end   = DateTime.new(*CONF.date_end.split('-').map(&:to_i))

articles = request('search', {
	tag: 'world/us-government-shutdown-2013',
    fromDate: date_start.to_s.split('T')[0],
    toDate: date_end.to_s.split('T')[0],
    showFields: 'body,wordcount'
})

handler = CONF.outfile ? File.open(CONF.outfile, 'w') : $stdout

handler.puts ["Title", "Section", "URL", "Links in body", "Internal", "External", "Link list"].join('|')

def get_shared_count
    # http://api.sharedcount.com/?url=
end

articles.each do |a|
	
    html = Nokogiri::HTML(a['fields']['body'])
    wc = html.inner_text.scan(/\w+/)

    puts [wc.length, a['webUrl'], wc.uniq.sort[0..8]].join("\t")

    #internal = links.select {|l| (l['href'] || '').match(/^http:\/\/www\.t?h?e?guardian.*/)}
	#handler.puts [a['webTitle'].gsub('|', '-'), a['sectionName'], a['webUrl'], links.size, internal.size, links.size - internal.size, links.map{|l| l['href']}.join(', ')].join('|')
    #links.each{|l| puts [a['webUrl'], l['href']].join("\t")}
end

puts "wrote output to #{CONF.outfile}" if CONF.outfile
